{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5106082d",
   "metadata": {},
   "source": [
    "# DataGrokr - Spark Assignment\n",
    "### Intern: Sumit Dhar \n",
    "### Date: 27th October, 2025"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e810536",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download all the datsets in zip format from:\n",
    "# https://datagrokranalytics-my.sharepoint.com/:u:/r/personal/naveen_gainedi_datagrokr_co/Documents/Public/Training/Courses/Spark/DatasetToCompleteTheSixSparkExercises.zip?csf=1&web=1&e=oln35S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "71008809",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "None\n",
      "c:\\Users\\Admin\\anaconda3\\envs\\testing_DG_pyspark\\python.exe\n",
      "c:\\Users\\Admin\\anaconda3\\envs\\testing_DG_pyspark\\python.exe\n"
     ]
    }
   ],
   "source": [
    "# Setting up the environment\n",
    "import os,sys\n",
    "print(os.environ.get(\"PYSPARK_PYTHON\"))\n",
    "print(os.environ.get(\"PYSPARK_DRIVER_PYTHON\"))\n",
    "\n",
    "os.environ[\"PYSPARK_PYTHON\"] = sys.executable\n",
    "os.environ[\"PYSPARK_DRIVER_PYTHON\"] = sys.executable\n",
    "\n",
    "print(os.environ.get(\"PYSPARK_PYTHON\"))\n",
    "print(os.environ.get(\"PYSPARK_DRIVER_PYTHON\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bb061bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing all the necessary libraries\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import StringType\n",
    "from pyspark.sql.window import Window\n",
    "from hashlib import sha256, md5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "110df031",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing the SparkSession\n",
    "spark = SparkSession.builder.appName(\"Spark_Assignment\").config(\"spark.driver.memory\", \"4g\").getOrCreate()\n",
    "\n",
    "products_file_path = \"products_parquet\" \n",
    "sales_file_path = \"sales_parquet\" \n",
    "sellers_file_path = \"sellers_parquet\" \n",
    "\n",
    "# Reading the Parquet file into respective DataFrames\n",
    "products = spark.read.parquet(products_file_path)\n",
    "orders = spark.read.parquet(sales_file_path)\n",
    "sellers = spark.read.parquet(sellers_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4390328e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Orders Schema:\n",
      "root\n",
      " |-- order_id: string (nullable = true)\n",
      " |-- product_id: string (nullable = true)\n",
      " |-- seller_id: string (nullable = true)\n",
      " |-- date: string (nullable = true)\n",
      " |-- num_pieces_sold: string (nullable = true)\n",
      " |-- bill_raw_text: string (nullable = true)\n",
      "\n",
      "After casting Orders Schema:\n",
      "root\n",
      " |-- order_id: integer (nullable = true)\n",
      " |-- product_id: integer (nullable = true)\n",
      " |-- seller_id: integer (nullable = true)\n",
      " |-- date: date (nullable = true)\n",
      " |-- num_pieces_sold: integer (nullable = true)\n",
      " |-- bill_raw_text: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Printing the schema for Orders\n",
    "print(\"Orders Schema:\")\n",
    "orders.printSchema()\n",
    "\n",
    "# Casting the datatypes for Orders\n",
    "orders = orders\\\n",
    "        .withColumn(\"order_id\", col(\"order_id\").cast(\"int\")) \\\n",
    "        .withColumn(\"product_id\", col(\"product_id\").cast(\"int\")) \\\n",
    "        .withColumn(\"seller_id\", col(\"seller_id\").cast(\"int\")) \\\n",
    "        .withColumn(\"date\", to_date(col(\"date\"), \"yyyy-MM-dd\")) \\\n",
    "        .withColumn(\"num_pieces_sold\", col(\"num_pieces_sold\").cast(\"int\"))\n",
    "\n",
    "print(\"After casting Orders Schema:\")\n",
    "orders.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "48148fc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+---------+----------+---------------+--------------------+\n",
      "|order_id|product_id|seller_id|      date|num_pieces_sold|       bill_raw_text|\n",
      "+--------+----------+---------+----------+---------------+--------------------+\n",
      "|       1|         0|        0|2020-07-10|             26|kyeibuumwlyhuwksx...|\n",
      "|       2|         0|        0|2020-07-08|             13|jfyuoyfkeyqkckwbu...|\n",
      "|       3|         0|        0|2020-07-05|             38|uyjihlzhzcswxcccx...|\n",
      "|       4|         0|        0|2020-07-05|             56|umnxvoqbdzpbwjqmz...|\n",
      "|       5|         0|        0|2020-07-05|             11|zmqexmaawmvdpqhih...|\n",
      "|       6|         0|        0|2020-07-01|             82|lmuhhkpyuoyslwmvX...|\n",
      "|       7|         0|        0|2020-07-04|             15|zoqweontumefxbgvu...|\n",
      "|       8|         0|        0|2020-07-08|             79|sgldfgtcxufasnvsc...|\n",
      "|       9|         0|        0|2020-07-10|             25|jnykelwjjebgkwgmu...|\n",
      "|      10|         0|        0|2020-07-08|              8|yywjfihneygcvfnyl...|\n",
      "+--------+----------+---------+----------+---------------+--------------------+\n",
      "only showing top 10 rows\n"
     ]
    }
   ],
   "source": [
    "orders.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "83cafd5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Products Schema:\n",
      "root\n",
      " |-- product_id: string (nullable = true)\n",
      " |-- product_name: string (nullable = true)\n",
      " |-- price: string (nullable = true)\n",
      "\n",
      "After casting Products Schema:\n",
      "root\n",
      " |-- product_id: integer (nullable = true)\n",
      " |-- product_name: string (nullable = true)\n",
      " |-- price: float (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Printing the schema for Products\n",
    "print(\"Products Schema:\")\n",
    "products.printSchema()\n",
    "\n",
    "# Casting the datatypes for Orders\n",
    "products = products\\\n",
    "        .withColumn(\"product_id\", col(\"product_id\").cast(\"int\")) \\\n",
    "        .withColumn(\"price\", col(\"price\").cast(\"float\")) \\\n",
    "\n",
    "print(\"After casting Products Schema:\")\n",
    "products.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f8381acb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------+-----+\n",
      "|product_id|product_name|price|\n",
      "+----------+------------+-----+\n",
      "|         0|   product_0| 22.0|\n",
      "|         1|   product_1| 30.0|\n",
      "|         2|   product_2| 91.0|\n",
      "|         3|   product_3| 37.0|\n",
      "|         4|   product_4|145.0|\n",
      "|         5|   product_5|128.0|\n",
      "|         6|   product_6| 66.0|\n",
      "|         7|   product_7|145.0|\n",
      "|         8|   product_8| 51.0|\n",
      "|         9|   product_9| 44.0|\n",
      "+----------+------------+-----+\n",
      "only showing top 10 rows\n"
     ]
    }
   ],
   "source": [
    "products.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9da56c13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sellers Schema:\n",
      "root\n",
      " |-- seller_id: string (nullable = true)\n",
      " |-- seller_name: string (nullable = true)\n",
      " |-- daily_target: string (nullable = true)\n",
      "\n",
      "After casting Sellers Schema:\n",
      "root\n",
      " |-- seller_id: integer (nullable = true)\n",
      " |-- seller_name: string (nullable = true)\n",
      " |-- daily_target: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Printing the schema for Sellers\n",
    "print(\"Sellers Schema:\")\n",
    "sellers.printSchema()\n",
    "\n",
    "# Casting the datatypes for Orders\n",
    "sellers = sellers\\\n",
    "        .withColumn(\"seller_id\", col(\"seller_id\").cast(\"int\")) \\\n",
    "        .withColumn(\"daily_target\", col(\"daily_target\").cast(\"integer\")) \\\n",
    "\n",
    "print(\"After casting Sellers Schema:\")\n",
    "sellers.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "56ccb41a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----------+------------+\n",
      "|seller_id|seller_name|daily_target|\n",
      "+---------+-----------+------------+\n",
      "|        0|   seller_0|     2500000|\n",
      "|        1|   seller_1|      257237|\n",
      "|        2|   seller_2|      754188|\n",
      "|        3|   seller_3|      310462|\n",
      "|        4|   seller_4|     1532808|\n",
      "|        5|   seller_5|     1199693|\n",
      "|        6|   seller_6|     1055915|\n",
      "|        7|   seller_7|     1946998|\n",
      "|        8|   seller_8|      547320|\n",
      "|        9|   seller_9|     1318051|\n",
      "+---------+-----------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sellers.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7d95a13",
   "metadata": {},
   "source": [
    "### Find out how many orders, how many products and how many sellers are in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f3ee6baa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total no. of orders: 20000040\n",
      "Total no. of products: 75000000\n",
      "Total no. of sellers: 10\n"
     ]
    }
   ],
   "source": [
    "# Counting total no of rows in each df\n",
    "orders_count = orders.count()\n",
    "products_count = products.count()\n",
    "sellers_count = sellers.count()\n",
    "\n",
    "print(f\"Total no. of orders: {orders_count}\")\n",
    "print(f\"Total no. of products: {products_count}\")\n",
    "print(f\"Total no. of sellers: {sellers_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cc5dcec",
   "metadata": {},
   "source": [
    "### How many products have been sold at least once? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "55320e37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of products sold at least once: 993429\n"
     ]
    }
   ],
   "source": [
    "# Filtering valid orders\n",
    "valid_orders = orders.filter(col('num_pieces_sold') > 0)\n",
    "\n",
    "# Selecting distinct products sold\n",
    "products_sold = valid_orders.select('product_id')\\\n",
    "                    .distinct().count()\n",
    "\n",
    "print(f\"Number of products sold at least once: {products_sold}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99da3759",
   "metadata": {},
   "source": [
    "### Which is the product contained in more orders?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "436949bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The most ordered product is: \n",
      "+----------+--------+\n",
      "|product_id|   count|\n",
      "+----------+--------+\n",
      "|         0|19000000|\n",
      "+----------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Filtering out the most ordered product grouping by product_id\n",
    "most_ordered_product = valid_orders.groupBy('product_id')\\\n",
    "                        .count()\\\n",
    "                        .orderBy(desc('count'))\\\n",
    "                        .limit(1)\n",
    "\n",
    "print(f\"The most ordered product is: \")\n",
    "most_ordered_product.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f8011f5",
   "metadata": {},
   "source": [
    "### What is the average revenue of the orders?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c509fcae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- product_id: integer (nullable = true)\n",
      " |-- order_id: integer (nullable = true)\n",
      " |-- seller_id: integer (nullable = true)\n",
      " |-- date: date (nullable = true)\n",
      " |-- num_pieces_sold: integer (nullable = true)\n",
      " |-- bill_raw_text: string (nullable = true)\n",
      " |-- product_name: string (nullable = true)\n",
      " |-- price: float (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Joining orders df with products df on similar product_id\n",
    "orders_with_price = valid_orders.join(products, on='product_id', how='inner')\n",
    "\n",
    "# Printing resultant schema\n",
    "orders_with_price.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "55fb5924",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- product_id: integer (nullable = true)\n",
      " |-- order_id: integer (nullable = true)\n",
      " |-- seller_id: integer (nullable = true)\n",
      " |-- date: date (nullable = true)\n",
      " |-- num_pieces_sold: integer (nullable = true)\n",
      " |-- bill_raw_text: string (nullable = true)\n",
      " |-- product_name: string (nullable = true)\n",
      " |-- price: float (nullable = true)\n",
      " |-- revenue: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Added new column 'revenue' after calculating - num_pieces_sold * prices\n",
    "orders_with_revenue = orders_with_price\\\n",
    "                        .withColumn('revenue', col('num_pieces_sold')*col('price'))\n",
    "\n",
    "# Printing resultant schema\n",
    "orders_with_revenue.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "41558bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating the average revenue\n",
    "average_revenue = orders_with_revenue.agg(avg('revenue').alias('average_revenue'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e9f87fd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n",
      "|   average_revenue|\n",
      "+------------------+\n",
      "|1246.1338560822878|\n",
      "+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "average_revenue.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72141ad7",
   "metadata": {},
   "source": [
    "### For each seller, what is the average % contribution of an order to the seller's daily quota?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e8c2bce6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- seller_id: integer (nullable = true)\n",
      " |-- product_id: integer (nullable = true)\n",
      " |-- order_id: integer (nullable = true)\n",
      " |-- date: date (nullable = true)\n",
      " |-- num_pieces_sold: integer (nullable = true)\n",
      " |-- bill_raw_text: string (nullable = true)\n",
      " |-- product_name: string (nullable = true)\n",
      " |-- price: float (nullable = true)\n",
      " |-- revenue: double (nullable = true)\n",
      " |-- seller_name: string (nullable = true)\n",
      " |-- daily_target: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Joining orders with sellers on similar seller_id\n",
    "orders_with_contribution = orders_with_revenue.join(sellers, on='seller_id', how='inner')\n",
    "\n",
    "# Printing resultant schema\n",
    "orders_with_contribution.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d082f66a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- seller_id: integer (nullable = true)\n",
      " |-- product_id: integer (nullable = true)\n",
      " |-- order_id: integer (nullable = true)\n",
      " |-- date: date (nullable = true)\n",
      " |-- num_pieces_sold: integer (nullable = true)\n",
      " |-- bill_raw_text: string (nullable = true)\n",
      " |-- product_name: string (nullable = true)\n",
      " |-- price: float (nullable = true)\n",
      " |-- revenue: double (nullable = true)\n",
      " |-- seller_name: string (nullable = true)\n",
      " |-- daily_target: integer (nullable = true)\n",
      " |-- percent_contribution: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Adding new column 'percent_contribution' after calculating - (revenue / daily_target) * 100\n",
    "orders_with_percent_contribution = orders_with_contribution.withColumn(\n",
    "    'percent_contribution',\n",
    "    (col('revenue') / col('daily_target'))*100\n",
    ")\n",
    "\n",
    "# Printing resultant schema\n",
    "orders_with_percent_contribution.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7e430db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating the average % contribution\n",
    "avg_percent_contribution = orders_with_percent_contribution\\\n",
    "                            .groupBy('seller_id', 'seller_name')\\\n",
    "                            .agg(avg('percent_contribution').alias('avg_percent_contribution'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "038351ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----------+------------------------+\n",
      "|seller_id|seller_name|avg_percent_contribution|\n",
      "+---------+-----------+------------------------+\n",
      "|        7|   seller_7|     0.19601246306317585|\n",
      "|        5|   seller_5|      0.3170589299015156|\n",
      "|        2|   seller_2|      0.5064829818617169|\n",
      "|        1|   seller_1|      1.4844178645806252|\n",
      "|        6|   seller_6|     0.36093852517481856|\n",
      "|        3|   seller_3|        1.23186781930548|\n",
      "|        8|   seller_8|      0.6946060998563962|\n",
      "|        4|   seller_4|     0.24841173704802327|\n",
      "|        9|   seller_9|     0.29052998156736454|\n",
      "|        0|   seller_0|     0.04443748977654746|\n",
      "+---------+-----------+------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "avg_percent_contribution.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d46fc1d2",
   "metadata": {},
   "source": [
    "### Who are the second most selling and the least selling persons (sellers) for each product?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d468dcff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Counting total orders per product per seller\n",
    "sellers_sales = orders.groupBy('product_id', 'seller_id')\\\n",
    "                .agg(count('*').alias('total_orders'))\n",
    "\n",
    "# Creating a window partitioned by product_id and ordered by total_orders DESC\n",
    "windowSpec_desc = Window.partitionBy('product_id').orderBy(desc('total_orders'))\n",
    "windowSpec_asc = Window.partitionBy('product_id').orderBy(asc('total_orders'))\n",
    "\n",
    "# Ranking sellers per product\n",
    "rank_sales_desc = sellers_sales.withColumn('rank', rank().over(windowSpec_desc))\n",
    "rank_sales_asc = sellers_sales.withColumn('rank', rank().over(windowSpec_asc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cdc1e7b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most selling persons:\n",
      "+----------+---------+------------+----+\n",
      "|product_id|seller_id|total_orders|rank|\n",
      "+----------+---------+------------+----+\n",
      "|  40579633|        9|           1|   2|\n",
      "|   2316238|        5|           1|   2|\n",
      "|   8916663|        5|           1|   2|\n",
      "|  61540351|        3|           1|   2|\n",
      "|  73385513|        2|           1|   2|\n",
      "|  26915351|        6|           1|   2|\n",
      "|  40193396|        9|           1|   2|\n",
      "|   2839667|        9|           1|   2|\n",
      "|  19978383|        8|           1|   2|\n",
      "|  28183035|        8|           1|   2|\n",
      "+----------+---------+------------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Selecting the second most selling persons\n",
    "second_most_selling = rank_sales_desc.filter(col('rank') == 2)\n",
    "print('Most selling persons:')\n",
    "second_most_selling.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a448de97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Least selling persons:\n",
      "+----------+---------+------------+----+\n",
      "|product_id|seller_id|total_orders|rank|\n",
      "+----------+---------+------------+----+\n",
      "|      1650|        6|           1|   1|\n",
      "|      1869|        9|           1|   1|\n",
      "|      2335|        2|           1|   1|\n",
      "|      2601|        4|           1|   1|\n",
      "|      2656|        8|           1|   1|\n",
      "|      2907|        5|           1|   1|\n",
      "|      2999|        8|           1|   1|\n",
      "|      2999|        7|           1|   1|\n",
      "|      3481|        3|           1|   1|\n",
      "|      4199|        3|           1|   1|\n",
      "+----------+---------+------------+----+\n",
      "only showing top 10 rows\n"
     ]
    }
   ],
   "source": [
    "# Selecting the least selling persons\n",
    "least_selling = rank_sales_asc.filter(col('rank') == 1)\n",
    "print('Least selling persons:')\n",
    "least_selling.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6e09830",
   "metadata": {},
   "source": [
    "### Who are those for product with `product_id = 0`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d8fcf789",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering sellers who sold product_id: 0\n",
    "sellers_with_p0 = orders.filter(col('product_id') == 0).select('seller_id').distinct()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d82ee3bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sellers who sold product with product_id: 0\n",
      "+---------+\n",
      "|seller_id|\n",
      "+---------+\n",
      "|        0|\n",
      "+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Sellers who sold product with product_id: 0')\n",
    "sellers_with_p0.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a32a70c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19000000"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cross-checking\n",
    "orders.filter(col('product_id') == 0).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e9ade1e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19000000"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orders.filter((col('product_id') == 0) & (col('seller_id') == 0)).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25e4b8d9",
   "metadata": {},
   "source": [
    "### Create a new column called \"hashed_bill\" defined as follows:\n",
    "\n",
    "- if the order_id is even: apply MD5 hashing iteratively to the bill_raw_text field, once for each 'A' (capital 'A') present in the text. E.g. if the bill text is 'nbAAnllA', you would apply hashing three times iteratively (only if the order number is even)\n",
    "\n",
    "- if the order_id is odd: apply SHA256 hashing to the bill text\n",
    "\n",
    "Finally, check if there are any duplicate on the new column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3d539434",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a user defined function\n",
    "def hash_bill(order_id, bill_raw_text):\n",
    "    if bill_raw_text is None:\n",
    "        return None\n",
    "    \n",
    "    if order_id % 2 == 0:\n",
    "        times = bill_raw_text.count('A')\n",
    "        hashed = bill_raw_text.encode()\n",
    "        for _ in range(times or 1):\n",
    "            hashed = md5(hashed).hexdigest().encode()\n",
    "        return hashed.decode()\n",
    "    else:\n",
    "        return sha256(bill_raw_text.encode()).hexdigest()\n",
    "\n",
    "hash_bill_udf = udf(hash_bill, StringType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ef0f071c",
   "metadata": {},
   "outputs": [],
   "source": [
    "orders_with_hash_bill = orders.withColumn(\n",
    "    'hashed_bill',\n",
    "    hash_bill_udf(col('order_id'), col('bill_raw_text'))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1b6aa807",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After applying hashing on even/odd order_id:\n",
      "+--------+----------+---------+----------+---------------+--------------------+--------------------+\n",
      "|order_id|product_id|seller_id|      date|num_pieces_sold|       bill_raw_text|         hashed_bill|\n",
      "+--------+----------+---------+----------+---------------+--------------------+--------------------+\n",
      "|       1|         0|        0|2020-07-10|             26|kyeibuumwlyhuwksx...|f6fa2a8be04a4ead6...|\n",
      "|       2|         0|        0|2020-07-08|             13|jfyuoyfkeyqkckwbu...|13af9a32eb8a31513...|\n",
      "|       3|         0|        0|2020-07-05|             38|uyjihlzhzcswxcccx...|416376a64cd652e7b...|\n",
      "|       4|         0|        0|2020-07-05|             56|umnxvoqbdzpbwjqmz...|7a73a2250f416bb81...|\n",
      "|       5|         0|        0|2020-07-05|             11|zmqexmaawmvdpqhih...|787d361b162a6aa1a...|\n",
      "|       6|         0|        0|2020-07-01|             82|lmuhhkpyuoyslwmvX...|4d0e2c457714c5d08...|\n",
      "|       7|         0|        0|2020-07-04|             15|zoqweontumefxbgvu...|4540f452a7c4d5049...|\n",
      "|       8|         0|        0|2020-07-08|             79|sgldfgtcxufasnvsc...|f598b6a84660aab07...|\n",
      "|       9|         0|        0|2020-07-10|             25|jnykelwjjebgkwgmu...|28b93c1c62caa2b97...|\n",
      "|      10|         0|        0|2020-07-08|              8|yywjfihneygcvfnyl...|51d35e22937a5f4f2...|\n",
      "+--------+----------+---------+----------+---------------+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('After applying hashing on even/odd order_id:')\n",
    "orders_with_hash_bill.limit(10).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c93a5fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking for duplicates with top 10 values.\n",
    "duplicate_hash_bill = orders_with_hash_bill.limit(10)\\\n",
    "                        .groupBy('hashed_bill')\\\n",
    "                        .count()\\\n",
    "                        .filter(col('count') > 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fedbdae6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duplicate_hash_bill.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "375a916c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No duplicates found in hashed_bill.\n"
     ]
    }
   ],
   "source": [
    "duplicate_hash_bill_count = duplicate_hash_bill.count()\n",
    "\n",
    "if duplicate_hash_bill_count > 0:\n",
    "    print(f\"There are {duplicate_hash_bill_count} duplicate hashed_bill entries.\")\n",
    "    duplicate_hash_bill.show(10)\n",
    "else:\n",
    "    print(\"No duplicates found in hashed_bill.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7601d250",
   "metadata": {},
   "outputs": [
    {
     "ename": "PythonException",
     "evalue": "\n  An exception was thrown from the Python worker. Please see the stack trace below.\nTraceback (most recent call last):\n  File \"c:\\Users\\Admin\\anaconda3\\envs\\testing_DG_pyspark\\lib\\socket.py\", line 720, in readinto\n    raise\nTimeoutError: timed out\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPythonException\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 10\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Checking for duplicates with all values\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# Note: As we were running codes on local system, nodes got crashed for huge volume of data and lead to 'TimeoutError: timed out'.\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Running it on google collab or highly capable machine won't crash.\u001b[39;00m\n\u001b[0;32m      5\u001b[0m duplicate_hash_bill \u001b[38;5;241m=\u001b[39m orders_with_hash_bill\\\n\u001b[0;32m      6\u001b[0m                         \u001b[38;5;241m.\u001b[39mgroupBy(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhashed_bill\u001b[39m\u001b[38;5;124m'\u001b[39m)\\\n\u001b[0;32m      7\u001b[0m                         \u001b[38;5;241m.\u001b[39mcount()\\\n\u001b[0;32m      8\u001b[0m                         \u001b[38;5;241m.\u001b[39mfilter(col(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcount\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m---> 10\u001b[0m duplicate_hash_bill_count \u001b[38;5;241m=\u001b[39m \u001b[43mduplicate_hash_bill\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcount\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m duplicate_hash_bill_count \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThere are \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mduplicate_hash_bill_count\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m duplicate hashed_bill entries.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Admin\\anaconda3\\envs\\testing_DG_pyspark\\lib\\site-packages\\pyspark\\sql\\classic\\dataframe.py:439\u001b[0m, in \u001b[0;36mDataFrame.count\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    438\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcount\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mint\u001b[39m:\n\u001b[1;32m--> 439\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mint\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcount\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32mc:\\Users\\Admin\\anaconda3\\envs\\testing_DG_pyspark\\lib\\site-packages\\py4j\\java_gateway.py:1362\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   1356\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[0;32m   1357\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[0;32m   1358\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[0;32m   1359\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[0;32m   1361\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[1;32m-> 1362\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1363\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1365\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[0;32m   1366\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(temp_arg, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_detach\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\Admin\\anaconda3\\envs\\testing_DG_pyspark\\lib\\site-packages\\pyspark\\errors\\exceptions\\captured.py:288\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[1;34m(*a, **kw)\u001b[0m\n\u001b[0;32m    284\u001b[0m converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n\u001b[0;32m    285\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(converted, UnknownException):\n\u001b[0;32m    286\u001b[0m     \u001b[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[38;5;66;03m# JVM exception message.\u001b[39;00m\n\u001b[1;32m--> 288\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m converted \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    289\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    290\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[1;31mPythonException\u001b[0m: \n  An exception was thrown from the Python worker. Please see the stack trace below.\nTraceback (most recent call last):\n  File \"c:\\Users\\Admin\\anaconda3\\envs\\testing_DG_pyspark\\lib\\socket.py\", line 720, in readinto\n    raise\nTimeoutError: timed out\n"
     ]
    }
   ],
   "source": [
    "# Checking for duplicates with all values\n",
    "# Note: As we were running codes on local system, nodes got crashed for huge volume of data and lead to 'TimeoutError: timed out'.\n",
    "# Running it on google collab or highly capable machine won't crash.\n",
    "\n",
    "duplicate_hash_bill = orders_with_hash_bill\\\n",
    "                        .groupBy('hashed_bill')\\\n",
    "                        .count()\\\n",
    "                        .filter(col('count') > 1)\n",
    "\n",
    "duplicate_hash_bill_count = duplicate_hash_bill.count()\n",
    "\n",
    "if duplicate_hash_bill_count > 0:\n",
    "    print(f\"There are {duplicate_hash_bill_count} duplicate hashed_bill entries.\")\n",
    "    duplicate_hash_bill.show(10)\n",
    "else:\n",
    "    print(\"No duplicates found in hashed_bill.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "401a7039",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stop the SparkSession\n",
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "testing_DG_pyspark",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
